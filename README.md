# üìä Atividade Pr√°tica ‚Äî Constru√ß√£o de Data Warehouse com PySpark e Arquitetura Medalh√£o

Este reposit√≥rio cont√©m a atividade pr√°tica destinada aos bolsistas participantes do projeto de Data Warehouse. O objetivo √© uma experi√™ncia de ponta a ponta na ingest√£o, modelagem e an√°lise de dados p√∫blicos usando **PySpark**, **Jupyter Notebooks** e a **Arquitetura Medalh√£o**.

---

## üìö Conceitos que precisam ser estudados

Antes de iniciar a atividade, os participantes devem compreender os seguintes t√≥picos:

* **Arquitetura de Dados**:

  * Conceito de Data Lakes e Data Warehouses
  * Arquitetura Medalh√£o: Landing ‚Üí Raw ‚Üí Trusted ‚Üí Refined
  * Conceito de Tabelas Fato e Dimens√£o
* **PySpark**:

  * Cria√ß√£o e manipula√ß√£o de DataFrames
  * Leitura e escrita de arquivos Delta
  * Opera√ß√µes de Join e transforma√ß√£o de dados
* **Delta Lake**:

  * Versionamento de dados
  * Time travel
  * Atualiza√ß√µes e merges
* **Jupyter Notebooks**:

  * Organiza√ß√£o modular de notebooks
  * Visualiza√ß√£o de resultados com `display()`, `show()` e gr√°ficos b√°sicos
* **Pagina√ß√£o em APIs REST**

  * Consumo de dados p√∫blicos via APIs RESTful
  * Tratamento de m√∫ltiplas p√°ginas de resultados

---

## üåê Endpoints p√∫blicos a serem utilizados

Os dados devem ser extra√≠dos dos portais de dados abertos do Governo Federal. Abaixo, est√£o as listadas as informa√ß√µes que devem compor o mini data warehouse:

1. **Empresas registradas na Receita Federal (base CNPJ):**
2. **Munic√≠pios do Brasil:**
3. **Natureza Jur√≠dica:**
4. **Empresas por munic√≠pio (fato):**
5. **Simples Nacional:**

Todos os endpoints exigem pagina√ß√£o ou m√∫ltiplas requisi√ß√µes. Deve  ser implementado o controle de p√°gina, cursor ou offset conforme a documenta√ß√£o de cada API. **Usar apenas uma amostra dos dados**

---

## üõ† Requisitos de ferramentas

Deve-se configurar um ambiente local com os seguintes requisitos:

* **Python 3.10+**
* **Apache Spark 3.5+** com suporte a Delta Lake
* **Bibliotecas Python**:

  * `pyspark`
  * `requests`
  * `delta-spark`
* **Jupyter Notebook** ou **JupyterLab**

---

## üèó Camadas a serem alimentadas (Arquitetura Medalh√£o)

A pipeline deve seguir a estrutura:

1. **Landing**: Dados brutos, diretamente como retornado pela API, em formato JSON ou CSV.
2. **Raw**: Convers√£o dos dados para esquema estruturado e padronizado (DataFrame).
3. **Trusted**: Aplica√ß√£o de regras de consist√™ncia, joins entre fatos e dimens√µes e enrichments.

---

## üîó Dados que devem ser cruzados

Os dados devem ser integrados da seguinte forma:

* A **tabela fato** ser√° composta pelos dados das empresas (CNPJ).
* Tabelas **dimens√µes**:

  * CNAE (atividade econ√¥mica)
  * Munic√≠pio (localidade)
  * Natureza Jur√≠dica
  * Simples Nacional (status tribut√°rio)

As rela√ß√µes a serem criadas s√£o:

| Tabela Fato | Chave de Relacionamento    | Tabela Dimens√£o   |
| ----------- | -------------------------- | ----------------- |
| CNPJ        | `codigo_cnae`              | CNAE              |
| CNPJ        | `codigo_municipio`         | Munic√≠pios (IBGE) |
| CNPJ        | `codigo_natureza_juridica` | Natureza Jur√≠dica |
| CNPJ        | `cnpj`                     | Simples Nacional  |

---

## üß© Particionamento

* A defini√ß√£o da **estrutura de particionamento** √© livre, podendo ser por UF, data de extra√ß√£o ou tipo de empresa.

---

## üíæ Formato e versionamento dos dados

* Todas as camadas devem ser escritas em **formato Delta Lake**.
* As camadas **RAW e TRUSTED** devem possuir **pelo menos duas vers√µes** de escrita para fins de demonstra√ß√£o de versionamento.
* Utilizar `merge` ou `overwrite` no Delta para reprocessamentos controlados.

---

## üìì Notebooks a serem constru√≠dos

1. **`01_coleta_dados.ipynb`**

   * Respons√°vel por consumir os dados dos endpoints e salvar na camada **Landing**.

2. **`02_preparacao_raw.ipynb`**

   * Transforma√ß√µes iniciais e salvamento estruturado na camada **RAW**.

3. **`03_transformacao_trusted.ipynb`**

   * Realiza√ß√£o de joins com dimens√µes e aplica√ß√£o de regras de qualidade de dados.

4. **`04_analise_resultados.ipynb`**

   * Exibir estat√≠sticas e visualiza√ß√µes dos dados.
   * Mostrar **vers√µes dispon√≠veis das tabelas Delta** com `DESCRIBE HISTORY`.

---

## ‚úÖ Crit√©rios de entrega

* Todos os notebooks devidamente comentados.
* Dados organizados em pastas por camada (LND, RAW, TRS).
* README.

---
